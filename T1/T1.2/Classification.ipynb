{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T1.2 - Solution A\n",
    "## Authors:\n",
    "- Leonardo Kaplan 1212509\n",
    "- Nino Fabrizio Tiriticco Lizardo 1113203"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pacotes usados\n",
    "import pandas as pd # Para pegar os dados dos arquivos\n",
    "from IPython.display import display # Para mostrar mais de uma informação em uma mesma célula\n",
    "import ast # Para transformar string/object em estruturas de dados (listas, dicionários, ...)\n",
    "import numpy as np # Para obter o total de valores por um atributo\n",
    "\n",
    "# modelos de classificação\n",
    "from sklearn import linear_model,datasets,svm,tree,neural_network\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#função de utilidade para separar teste e treinamento\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#funções de utilidade para metricas\n",
    "from sklearn.metrics import mean_squared_error, r2_score, accuracy_score, confusion_matrix, precision_score, recall_score,f1_score\n",
    "\n",
    "#funções de utilidade para seleção de features\n",
    "from sklearn.feature_selection import VarianceThreshold,SelectKBest,chi2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "\n",
    "# isto é para usarmos markdown no meio de uma célula Python\n",
    "from IPython.display import Markdown, display\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "    \n",
    "import random\n",
    "random.seed(1001001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Carregando dados de cada um dos arquivos\n",
    "data = pd.read_csv('in/winequality-red.csv',sep=';')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plotando combinações de features. Foi útil para vermos que não existem dependências ou independências claras.\n",
    "#sns.set(style=\"ticks\")\n",
    "#sns.pairplot(data,hue=\"quality\")\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mapa de correlações. útil para vermos que features devem ser mais 'pesadas' ou excluídas\n",
    "plt.subplots(figsize=(10,10))\n",
    "sns.heatmap(data.corr(),vmax=1,square=True,annot=True,cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']\n",
    "X = data[features]\n",
    "Y = data['quality']\n",
    "\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,random_state=random.randrange(0,100),test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# função para apresentar resultados de uma estimativa. Mostra o valor estimado (em azul) sobre o valor real (em vermelho).\n",
    "def present(x,y,h):\n",
    "    fig = plt.figure(figsize = (15,15))\n",
    "    size = len(data.columns)\n",
    "    for i in range(0,size-1):\n",
    "        ax = fig.add_subplot(math.ceil(math.sqrt(size-1)), math.ceil(math.sqrt(size-1)), i+1)\n",
    "        ax.scatter(x.iloc[:,i], y,  color='red')\n",
    "        ax.scatter(x.iloc[:,i], h, color='blue')\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Realiza um teste de modelo: treinando, gerando valores e avaliando diversas métricas. \n",
    "# Retornamos os dados para serem plotados com a present se preciso.\n",
    "def test(regr,X_train,Y_train,X_test,Y_test):\n",
    "    regr.fit(X_train, Y_train)\n",
    "    Y_pred = regr.predict(X_test)\n",
    "    metrics = {\n",
    "        'mse': mean_squared_error(Y_test, Y_pred),\n",
    "        'r2':r2_score(Y_test, Y_pred),\n",
    "        'accuracy':accuracy_score(Y_test, Y_pred), \n",
    "        'precision':precision_score(Y_test, Y_pred, average='macro'), \n",
    "        'recall':recall_score(Y_test, Y_pred, average='macro'),\n",
    "        'f1':f1_score(Y_test, Y_pred, average='macro')\n",
    "    }\n",
    "    return Y_pred,metrics#,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Métodos escolhidos e configurações escolhidas. \n",
    "# Determinamos as configurações experimentando, utilizando a test e a present. (na célula abaixo)\n",
    "# Não mantive um registro dos experimentos realizados, mas variamos na mão ou com iterações. \n",
    "# Acho que não muito por acaso, os valores default costumavam ser os mais ótimos\n",
    "methods = [\n",
    "        linear_model.LogisticRegressionCV(),\n",
    "        svm.SVC(),\n",
    "        linear_model.SGDClassifier(max_iter=1000,tol=1e-3,loss=\"huber\"),\n",
    "        NearestCentroid(),\n",
    "        KNeighborsClassifier(n_neighbors=5),\n",
    "        tree.DecisionTreeClassifier(),\n",
    "        neural_network.MLPClassifier(solver='lbfgs')\n",
    "    ]\n",
    "#função que testa todos os métodos, retornando uma lista com as métricas\n",
    "def test_all(X_train,Y_train,X_test,Y_test):\n",
    "    metrics = []\n",
    "    for method in methods:\n",
    "        #print(method.__class__.__name__)\n",
    "        #print()\n",
    "        Y_pred,metric = test(method,X_train,Y_train,X_test,Y_test)\n",
    "        #print()\n",
    "        metrics = metrics + [metric]\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aqui variávamos o método escolhido para teste e na célula acima, as configurações\n",
    "Y_pred,_ = test(methods[0],X_train,Y_train,X_test,Y_test)\n",
    "present(X_test,Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aqui foi um momento de exploração utilizando o KNN e vendo onde teriamos a melhor relação erro/acurácia.\n",
    "# Dessa forma, acharíamos o número de clusters ótimo, o que indica uma boa direção para o número de features.\n",
    "es = []\n",
    "ss = []\n",
    "xs = list(range(1,12))\n",
    "for i in xs:\n",
    "    Y_pred,met = test(KNeighborsClassifier(n_neighbors=i),X_train,Y_train,X_test,Y_test)\n",
    "    es += [met['mse']]\n",
    "    ss += [met['accuracy']]\n",
    "plt.scatter(xs, es,  color='red')\n",
    "plt.scatter(xs, ss,  color='green')\n",
    "plt.show()\n",
    "#present(X_test,Y_test,Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aqui vemos o impacto de cada feature na qualidade (não foi muito útil)\n",
    "features = ['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
    "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
    "       'pH', 'sulphates', 'alcohol']\n",
    "X = data[features]\n",
    "Y = data['quality']\n",
    "sns.pairplot(data,x_vars=features,y_vars='quality',kind='reg',size=7,aspect=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# utilizamos diversos algoritmos de filtragem de feature automática.\n",
    "X = data[features]\n",
    "print(np.shape(X))\n",
    "sel = VarianceThreshold(threshold=(.8 * (1 - .8)))\n",
    "X1 = sel.fit_transform(X)\n",
    "print(np.shape(X1))\n",
    "X2 = SelectKBest(chi2, k=2).fit_transform(X, Y)\n",
    "print(np.shape(X2))\n",
    "# Este 5 veio devido ao KNN e ao resultado do variance threshold\n",
    "X3 = SelectKBest(chi2, k=5).fit_transform(X, Y)\n",
    "print(np.shape(X3))\n",
    "#sns.pairplot(data,x_vars=features,y_vars='quality',kind='reg',size=7,aspect=0.5)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#criamos 3 sub-datasets baseado nas filtragens\n",
    "rand = random.randrange(0,100)\n",
    "X1_train,X1_test,Y1_train,Y1_test=train_test_split(X1,Y,random_state=rand,test_size=0.25)\n",
    "X2_train,X2_test,Y2_train,Y2_test=train_test_split(X2,Y,random_state=rand,test_size=0.25)\n",
    "X3_train,X3_test,Y3_train,Y3_test=train_test_split(X3,Y,random_state=rand,test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "metric_results = [\n",
    "    test_all(X_train,Y_train,X_test,Y_test),\n",
    "    test_all(X1_train,Y1_train,X1_test,Y1_test),\n",
    "    test_all(X2_train,Y2_train,X2_test,Y2_test),\n",
    "    test_all(X3_train,Y3_train,X3_test,Y3_test)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# função para exibir um dataframe estilizado baseado no que é importante para a métrica escolhida\n",
    "def show(metric,views):\n",
    "    data = {\n",
    "        'no filtering':[x[metric] for x in metric_results[0]], \n",
    "        'variance (80%)':[x[metric] for x in metric_results[1]],\n",
    "        'chi2 k = 2':[x[metric] for x in metric_results[2]],\n",
    "        'chi2 k =5':[x[metric] for x in metric_results[3]]\n",
    "    }\n",
    "    tabela = pd.DataFrame(data=data,index=[method.__class__.__name__ for method in methods])\n",
    "    printmd('# '+ metric)\n",
    "    return tabela.style.applymap(views[0]).apply(views[1]).apply(views[2], axis=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_big_red(val):\n",
    "    color = 'red' if val > 1 else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "def highlight_min(s):\n",
    "    is_min = s == s.min()\n",
    "    return ['background-color: yellow' if v else '' for v in is_min]\n",
    "def color_negative_red(val):\n",
    "    color = 'red' if val < 0 else 'black'\n",
    "    return 'color: %s' % color\n",
    "\n",
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]\n",
    "\n",
    "def highlight_total_max(data):\n",
    "    attr = 'background-color: {}'.format('cyan')\n",
    "    is_max = data == data.max().max()\n",
    "    return pd.DataFrame(np.where(is_max, attr, ''),index=data.index, columns=data.columns)\n",
    "\n",
    "def highlight_total_min(data):\n",
    "    attr = 'background-color: {}'.format('cyan')\n",
    "    is_min = data == data.min().min()\n",
    "    return pd.DataFrame(np.where(is_min, attr, ''),index=data.index, columns=data.columns)\n",
    "\n",
    "metrics_show = {\n",
    "        'mse': (color_big_red,highlight_min,highlight_total_min),\n",
    "        'r2':(color_negative_red,highlight_max,highlight_total_max),\n",
    "        'accuracy':(color_negative_red,highlight_max,highlight_total_max), \n",
    "        'precision':(color_negative_red,highlight_max,highlight_total_max), \n",
    "        'recall':(color_negative_red,highlight_max,highlight_total_max),\n",
    "        'f1':(color_negative_red,highlight_max,highlight_total_max)\n",
    "}\n",
    "metrics_show_keys = list(metrics_show.keys())\n",
    "metrics_show_values = list(metrics_show.values())\n",
    "def show_metric(i):\n",
    "    return show(metrics_show_keys[i],metrics_show_values[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Da forma que escrevi as funções, o melhor método do dataset está em amarelo, o melhor método/dataset está em ciano e valores absurdos (acima de 1 ou abaixo de 0 dependendo do método) estão em vermelho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_metric(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_metric(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_metric(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_metric(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_metric(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_metric(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusão: \n",
    "### Filtrar features não trouxe resultados melhores na maior parte das métricas, com exceção da acurácia (que muitos consideram importante (não sei se realmente muito mais que as outras)). Acredito que tenha tipo algum impacto sobre a performance em tempo e memória, mas não medi isso. É bem possível que estes impactos tenham sido bem marginais também.\n",
    "### Sobre os métodos, os melhores foram redes neurais e árvore de decisão. Fico dividido sobre qual eu recomendaria para alguém. Fico tentado a me basear nas métricas de performance das redes porém acho que tenho mais noção do que está acontecendo no caso da árvore de decisão. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
